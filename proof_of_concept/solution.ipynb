{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdeb7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tomli\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from chromadb import PersistentClient\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.document_loaders import BaseLoader\n",
    "from langchain_cohere import CohereEmbeddings,ChatCohere\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e20aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "# API key from free tier provided, will be deactivated after one week.\n",
    "# Loading configs and API Keys\n",
    "cohere_api_key = os.getenv('COHERE_API_KEY')\n",
    "with open(\"../parameters.toml\", \"rb\") as params:\n",
    "          config = tomli.load(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9e27f0",
   "metadata": {},
   "source": [
    "#### Data Ingestion and Vector store creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ccf7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_path = config[\"rag\"][\"vector_store_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b18ec2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Persistent Client\n",
    "persistent_client = PersistentClient(path=vector_store_path)\n",
    "# Modifiable according to session\n",
    "collection_name = config[\"rag\"][\"collection_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2510ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Document Loader\n",
    "class FinancialDocumentLoader(BaseLoader):\n",
    "    \"\"\"\n",
    "    Custom loader for parsing financial documents from a plain text file.\n",
    "\n",
    "    Expected format:\n",
    "        Document 1: <Title Line>\n",
    "        <Content>\n",
    "        Document 2: <Title Line>\n",
    "        <Content>\n",
    "        ...\n",
    "\n",
    "    Attributes:\n",
    "        file_path (str): Path to the text file containing the financial documents.\n",
    "\n",
    "    Methods:\n",
    "        load(): Parses the file and returns a list of `Document` objects, each containing\n",
    "                the content and metadata (source and title) for a single financial organization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def load(self):\n",
    "        with open(self.file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # Used regex to split by -> Document:X\n",
    "        raw_docs = re.split(r'\\nDocument \\d+: ', text)\n",
    "        documents = []\n",
    "\n",
    "        for i, chunk in enumerate(raw_docs[1:], start=1):  # Skiped the first empty split\n",
    "            title_end = chunk.find(\"\\n\")\n",
    "            title = chunk[:title_end].strip()\n",
    "            content = chunk[title_end+1:].strip()\n",
    "            metadata = {\"source\": f\"Document {i}\", \"title\": title}\n",
    "\n",
    "            documents.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4f1d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest data\n",
    "source_data_path = config[\"rag\"][\"source_file_location\"]\n",
    "loader = FinancialDocumentLoader(source_data_path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069a1987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Document 1', 'title': 'Blue Horizon Investments'}, page_content='Description:\\nBased in London, Blue Horizon Investments is known for its innovative portfolio strategies. However, irregular transaction patterns and rapid, unexplained fund movements have raised concerns about possible insider trading and manipulation.'),\n",
       " Document(metadata={'source': 'Document 2', 'title': 'Cascade Capital Management'}, page_content='Description:\\nCascade Capital Management, a venture capital firm specializing in tech investments, has grown rapidly but relies on a complex network of subsidiary shell companies. This structure has attracted regulatory scrutiny regarding transparency and compliance.'),\n",
       " Document(metadata={'source': 'Document 3', 'title': 'Eclipse Global Holdings'}, page_content='Description:\\nEclipse Global Holdings is a diversified conglomerate with interests in multiple sectors. Recent investigations have linked several of its subsidiaries to irregular contract awards and suspected kickback schemes, raising red flags about its internal controls.'),\n",
       " Document(metadata={'source': 'Document 4', 'title': 'Gemini Asset Management'}, page_content='Description:\\nServing high-net-worth clients in Asia, Gemini Asset Management has recently been spotlighted for unusually high commissions and inconsistent portfolio reporting. These anomalies have sparked concerns over potential money laundering and fraudulent practices.'),\n",
       " Document(metadata={'source': 'Document 5', 'title': 'Helix Fintech Solutions'}, page_content='Description:\\nHelix Fintech Solutions is a rapidly growing startup in the financial technology space. Its strategy of partnering with numerous unregulated advisors has resulted in a patchwork of compliance practices, prompting internal reviews for potential fraud and mismanagement of client funds.'),\n",
       " Document(metadata={'source': 'Document 6', 'title': 'Delta Trade Corporation'}, page_content='Description:\\nDelta Trade Corporation operates across Europe and Asia with a long-standing reputation for transparency. Its high-frequency trading is supported by robust compliance measures and detailed reporting, ensuring adherence to regulatory standards.'),\n",
       " Document(metadata={'source': 'Document 7', 'title': 'Falcon Secure Bank'}, page_content='Description:\\nFalcon Secure Bank is a digital-only institution acclaimed for its cutting-edge cybersecurity and rigorous internal audits. The bank consistently demonstrates strong compliance practices and transparent operations, earning the trust of its customers and regulators alike.'),\n",
       " Document(metadata={'source': 'Document 8', 'title': 'Ionex Brokerage Services'}, page_content='Description:\\nIonex Brokerage Services is a popular online platform in Europe with a proven track record of consistent performance. Its transaction patterns are steady and well-documented, with no known irregularities or red flags in its operations.'),\n",
       " Document(metadata={'source': 'Document 9', 'title': 'Jupiter Commodities Exchange'}, page_content='Description:\\nJupiter Commodities Exchange has been a cornerstone in the raw materials trading industry for decades. The exchange maintains transparent trading practices and robust oversight, ensuring that all activities comply with regulatory standards.'),\n",
       " Document(metadata={'source': 'Document 10', 'title': 'Kepler Financial Innovations'}, page_content='Description:\\nKepler Financial Innovations is renowned for its ethical practices and state-of-the-art risk management. With a focus on transparency and regulatory compliance, the firm has built a reputation as a trusted player in the financial market.'),\n",
       " Document(metadata={'source': 'Document 11', 'title': 'Lunar Investment Group'}, page_content='Description:\\nLunar Investment Group, based in Singapore, is a diversified investment firm with an impeccable compliance record. Its operations are characterized by detailed documentation and transparent fund management practices, ensuring full adherence to regulatory requirements.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f68627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing new line char to save processed tokens\n",
    "for doc in docs:\n",
    "    doc.page_content = ' '.join(doc.page_content.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0550184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedder instantiated\n",
    "embeddings = CohereEmbeddings(\n",
    "    cohere_api_key=cohere_api_key,\n",
    "    model=config[\"llm\"][\"embedding_model\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afec0e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_18548\\178591780.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store_from_client = Chroma(\n"
     ]
    }
   ],
   "source": [
    "# Vector store instantiated\n",
    "vector_store_from_client = Chroma(\n",
    "        client=persistent_client,\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embeddings,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80acab75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bad90191-dbe2-4f2f-ad11-d08e8c1f5755',\n",
       " '9c9025b0-5580-468f-8b00-208b28522482',\n",
       " 'c0056089-6439-463f-be75-1ae0417890e6',\n",
       " '5c09f301-477a-46a9-8095-a0a70e9a221d',\n",
       " 'b7eeccf1-fff9-4f3d-9324-71cc3b631325',\n",
       " '696efc84-166a-49af-8520-91c93d90a0ab',\n",
       " 'ac6915da-daf5-4a48-959c-886db74835bc',\n",
       " '7373d29a-a994-4eaf-baf4-aa29c6c8a964',\n",
       " '61392672-4d54-4537-a4c2-34218be61b8a',\n",
       " '24042249-85b3-4b73-a69d-69882b802cd9',\n",
       " 'dcf2fefe-754c-42ef-bd10-720eae5dc161']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding Documents into the vector store\n",
    "vector_store_from_client.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3523dc5",
   "metadata": {},
   "source": [
    "#### Creating three types of retrievers - MMR (Maximal Marginal Relevance), Similarity Score Threshold and Similarity Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed7e465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the retriever (Maximal Marginal Relevance)\n",
    "retriever_mmr = vector_store_from_client.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={\n",
    "        \"k\": 4,              # number of documents to return\n",
    "        \"fetch_k\": 9,        # number of documents to consider before reranking with MMR\n",
    "        \"lambda_mult\": 0.7   # high lambda focuses more on relevance than diversity\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6194d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the retriever (Similarity Score Threshold)\n",
    "retriever_sst = vector_store_from_client.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", \n",
    "    search_kwargs={\n",
    "        \"score_threshold\": 0.4\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6e0f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the retriever (Similarity Search)\n",
    "retriever_ss = vector_store_from_client.as_retriever(\n",
    "    search_type='similarity',\n",
    "    search_kwargs={\n",
    "        \"k\": 4              \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d40ea7",
   "metadata": {},
   "source": [
    "### Comparing the Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2b54dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes all retrievers return a list of Documents\n",
    "def compare_retrievers(query, retrievers: dict, embedding_model):\n",
    "    \"\"\"\n",
    "    Compare MMR, similarity, and threshold-based retrievers for a given query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The user query.\n",
    "        retrievers (dict): Dictionary of retriever_name -> retriever_instance.\n",
    "        embedding_model: Embedding model (e.g., OpenAIEmbeddings()).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Comparison table of latency and relevance.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for name, retriever in retrievers.items():\n",
    "        start_time = time.time()\n",
    "        docs = retriever.invoke(query)\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "\n",
    "        # Compute cosine similarity between query and each doc\n",
    "        similarities = []\n",
    "        for doc in docs:\n",
    "            doc_embedding = embedding_model.embed_query(doc.page_content)  \n",
    "            doc_vec = np.array(doc_embedding).reshape(1, -1)\n",
    "            query_embedding = embedding_model.embed_query(query)\n",
    "            query_vec = np.array(query_embedding).reshape(1, -1)\n",
    "            sim = cosine_similarity(query_vec, doc_vec)[0][0]\n",
    "            similarities.append(sim)\n",
    "\n",
    "        avg_relevance = np.mean(similarities) if similarities else 0.0\n",
    "\n",
    "        results.append({\n",
    "            \"Retriever\": name,\n",
    "            \"Retrieved_Docs\": len(docs),\n",
    "            \"Avg Relevance (Cosine)\": round(avg_relevance, 4),\n",
    "            \"Retrieval Time (s)\": round(duration, 4)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d69d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retriever</th>\n",
       "      <th>Retrieved_Docs</th>\n",
       "      <th>Avg Relevance (Cosine)</th>\n",
       "      <th>Retrieval Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMR</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4525</td>\n",
       "      <td>0.3770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Similarity</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4596</td>\n",
       "      <td>0.3561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Similarity + Threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Retriever  Retrieved_Docs  Avg Relevance (Cosine)  \\\n",
       "0                     MMR               4                  0.4525   \n",
       "1              Similarity               4                  0.4596   \n",
       "2  Similarity + Threshold               0                  0.0000   \n",
       "\n",
       "   Retrieval Time (s)  \n",
       "0              0.3770  \n",
       "1              0.3561  \n",
       "2              0.3606  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your retrievers\n",
    "retrievers = {\n",
    "    \"MMR\": retriever_mmr,\n",
    "    \"Similarity\": retriever_ss,\n",
    "    \"Similarity + Threshold\": retriever_sst\n",
    "}\n",
    "\n",
    "query = \"Which organizations show signs of complex laundering structures?\"\n",
    "\n",
    "comparison_df = compare_retrievers(query, retrievers, embeddings)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56acc893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Document 7', 'title': 'Falcon Secure Bank'}, page_content='Description: Falcon Secure Bank is a digital-only institution acclaimed for its cutting-edge cybersecurity and rigorous internal audits. The bank consistently demonstrates strong compliance practices and transparent operations, earning the trust of its customers and regulators alike.'),\n",
       " Document(metadata={'source': 'Document 7', 'title': 'Falcon Secure Bank'}, page_content='Description: Falcon Secure Bank is a digital-only institution acclaimed for its cutting-edge cybersecurity and rigorous internal audits. The bank consistently demonstrates strong compliance practices and transparent operations, earning the trust of its customers and regulators alike.'),\n",
       " Document(metadata={'source': 'Document 7', 'title': 'Falcon Secure Bank'}, page_content='Description: Falcon Secure Bank is a digital-only institution acclaimed for its cutting-edge cybersecurity and rigorous internal audits. The bank consistently demonstrates strong compliance practices and transparent operations, earning the trust of its customers and regulators alike.'),\n",
       " Document(metadata={'source': 'Document 6', 'title': 'Delta Trade Corporation'}, page_content='Description: Delta Trade Corporation operates across Europe and Asia with a long-standing reputation for transparency. Its high-frequency trading is supported by robust compliance measures and detailed reporting, ensuring adherence to regulatory standards.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_ss.invoke(\"Which institutions demonstrate strong internal audits and transparent operations?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8192edcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Document 7', 'title': 'Falcon Secure Bank'}, page_content='Description: Falcon Secure Bank is a digital-only institution acclaimed for its cutting-edge cybersecurity and rigorous internal audits. The bank consistently demonstrates strong compliance practices and transparent operations, earning the trust of its customers and regulators alike.'),\n",
       " Document(metadata={'source': 'Document 7', 'title': 'Falcon Secure Bank'}, page_content='Description: Falcon Secure Bank is a digital-only institution acclaimed for its cutting-edge cybersecurity and rigorous internal audits. The bank consistently demonstrates strong compliance practices and transparent operations, earning the trust of its customers and regulators alike.'),\n",
       " Document(metadata={'source': 'Document 6', 'title': 'Delta Trade Corporation'}, page_content='Description: Delta Trade Corporation operates across Europe and Asia with a long-standing reputation for transparency. Its high-frequency trading is supported by robust compliance measures and detailed reporting, ensuring adherence to regulatory standards.'),\n",
       " Document(metadata={'source': 'Document 10', 'title': 'Kepler Financial Innovations'}, page_content='Description: Kepler Financial Innovations is renowned for its ethical practices and state-of-the-art risk management. With a focus on transparency and regulatory compliance, the firm has built a reputation as a trusted player in the financial market.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_mmr.invoke(\"Which institutions demonstrate strong internal audits and transparent operations?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bba41b",
   "metadata": {},
   "source": [
    "### Choosing maximal marginal relevance since \n",
    "- Upon multiple experiments the avg relevance was similar for both MMR and Similarity but the retrieval time is less in latter.\n",
    "- But upon further experiments, it was noted that similarity search resulted in repeated retrievals, ignoring the relevance\n",
    "- Similarity + Threshold as a high chance of missing documents (fetched only 1 relevant doc at threshold - 0.4)\n",
    "- MMR chosen to avoid redudancy and maintain high relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1386929",
   "metadata": {},
   "source": [
    "### Prompt Engineering + LLM to construct coherent answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "154d7eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatCohere(cohere_api_key=cohere_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434d7e78",
   "metadata": {},
   "source": [
    "### Prompt Variations to test against - \n",
    "- Base Prompt (To establish a baseline for comparision)\n",
    "- Risk Focused Framing (Emphasize the goal of risk detection for more focused and structured answers.)\n",
    "- Regulatory tone with Evaluation Metric (Make the LLM evaluate)\n",
    "- Chain-of-Thought Prompting (Encourage the LLM to reason)\n",
    "- Focused Extraction (Improve precision by restricting to relevant names)\n",
    "- Summarize + Analyze (Make the LLM reprocess the data to improve its understanding before answering.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a716c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPLATES\n",
    "\n",
    "# Base Prompt\n",
    "TEMPLATE_base = \"\"\"\n",
    "Use the following context to answer the question:\n",
    "{retrieved_documents}\n",
    "Question: {query}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Risk Focused Framing\n",
    "TEMPLATE_risk_focused = \"\"\"\n",
    "You are a compliance analyst. Based on the context below, \n",
    "identify any signs of financial crime or compliance risks.\n",
    "Context:\n",
    "{retrieved_documents}\n",
    "Query: {query}\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "# Regulatory tone + eval metric\n",
    "TEMPLATE_regu_eval = \"\"\"\n",
    "As a regulator, assess the following organizations based on context:\n",
    "{retrieved_documents}\n",
    "\n",
    "For each entity mentioned in the context:\n",
    "- Assign a **Compliance Risk Level**: High, Medium, or Low\n",
    "- Justify the rating in one sentence using evidence from the context.\n",
    "Be precise, formal, and analytical.\n",
    "\n",
    "Query: {query}\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "# Chain of Thought\n",
    "TEMPLATE_CoT = \"\"\"\n",
    "Analyze the context below step by step and determine\n",
    "if any organizations show patterns related to financial misconduct.\n",
    "Context:\n",
    "{retrieved_documents}\n",
    "Query: {query}\n",
    "Step-by-step analysis:\n",
    "\"\"\"\n",
    "\n",
    "# Focused Extraction\n",
    "TEMPLATE_focus_extract = \"\"\"\n",
    "Read the context below and extract only the organization names that \n",
    "match the criteria in the query.\n",
    "Context:\n",
    "{retrieved_documents}\n",
    "Query: {query}\n",
    "Matching organizations:\n",
    "\"\"\"\n",
    "\n",
    "# Summarize + Analyse\n",
    "TEMPLATE_summarize = \"\"\"\n",
    "Summarize the key characteristics of each organization in the context, \n",
    "then answer the query.\n",
    "Context:\n",
    "{retrieved_documents}\n",
    "Summary + Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1f46286",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(TEMPLATE_regu_eval)\n",
    "chain = ({'retrieved_documents':retriever_ss,\n",
    "         'query':RunnablePassthrough()} | prompt_template | chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f1e65bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chain.invoke(\"Which organisations show signs of potential money laundering through complex structures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3f71003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Gemini Asset Management**  \n",
      "**Compliance Risk Level**: High  \n",
      "**Justification**: Gemini Asset Management exhibits high compliance risk due to unusually high commissions and inconsistent portfolio reporting, which are red flags for potential money laundering and fraudulent practices.  \n",
      "\n",
      "**Eclipse Global Holdings**  \n",
      "**Compliance Risk Level**: High  \n",
      "**Justification**: Eclipse Global Holdings faces high compliance risk due to irregular contract awards and suspected kickback schemes across its subsidiaries, indicating weak internal controls and potential illicit financial activities.  \n",
      "\n",
      "**Organizations showing signs of potential money laundering through complex structures**:  \n",
      "- **Gemini Asset Management**: The anomalies in commissions and portfolio reporting suggest potential layering or integration of illicit funds through complex financial transactions.  \n",
      "- **Eclipse Global Holdings**: The involvement of multiple subsidiaries in irregular contract awards and kickback schemes indicates a complex structure that could facilitate money laundering.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d95336",
   "metadata": {},
   "source": [
    "### Comparing results from prompt variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edc8e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templates = {\n",
    "    \"base\": TEMPLATE_base,\n",
    "    \"risk_focused\": TEMPLATE_risk_focused,\n",
    "    \"regulatory tone with evaluation\" : TEMPLATE_regu_eval,\n",
    "    \"chain_of_thought\": TEMPLATE_CoT,\n",
    "    \"focused_extraction\": TEMPLATE_focus_extract,\n",
    "    \"summarize_analyze\": TEMPLATE_summarize\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f41f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prompts(prompt_templates, query):\n",
    "    \"\"\"\n",
    "    Evaluates multiple prompt templates for a given query and returns performance metrics.\n",
    "\n",
    "    This function runs a set of prompt templates through a predefined LLM chain (including a retriever\n",
    "    and chat model) and evaluates their performance based on token usage and response time.\n",
    "    It returns the outputs along with performance metrics in a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        prompt_templates (dict): \n",
    "            A dictionary where keys are the names of the prompt templates and values are template strings.\n",
    "        query (str): \n",
    "            The user query to be evaluated across all prompt templates.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: \n",
    "            A DataFrame containing:\n",
    "                - 'Prompt Name': Name of the prompt template\n",
    "                - 'Output': LLM's generated response\n",
    "                - 'Tokens Count - Input': Number of tokens in the prompt input\n",
    "                - 'Tokens Count - Output': Number of tokens in the generated output\n",
    "                - 'Tokens Consumed': Total tokens used (input + output)\n",
    "                - 'Response Time (s)': Time taken to generate the response (in seconds)\n",
    "\n",
    "    Note:\n",
    "        - The function assumes existence of a `retriever_mmr` object for document retrieval \n",
    "          and a `chat` object representing the LLM pipeline.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for name, template in prompt_templates.items():\n",
    "        prompt_template = PromptTemplate.from_template(template)\n",
    "        chain = ({'retrieved_documents':retriever_mmr,\n",
    "         'query':RunnablePassthrough()} | prompt_template | chat)\n",
    "\n",
    "        start_time = time.time()\n",
    "        response = chain.invoke(query)\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        token_usage = response.additional_kwargs['token_count']\n",
    "\n",
    "        results.append({\n",
    "            \"Prompt Name\": name,\n",
    "            \"Output\": response.content,\n",
    "            \"Tokens Count - Input\": token_usage['input_tokens'],\n",
    "            \"Tokens Count - Output\": token_usage['output_tokens'],\n",
    "            \"Tokens Consumed\": sum(token_usage.values()),\n",
    "            \"Response Time (s)\": round(elapsed_time, 2),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbd83ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_prompts(prompt_templates,\"Which organisations show signs of potential money laundering through complex structures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f456cb40",
   "metadata": {},
   "source": [
    "### Initial observations \n",
    "- Depending on the usecase prompt variation can be chosen \n",
    "- If the task is focused solely on entity extraction, focused_extraction is good with response time of 3.10 seconds. \n",
    "- It is still required to dive deeper into each prompt variation before finalising since we still have no idea if the answers generated are relevant (Precision, Recall) \n",
    "- Map them to a clarity score. \n",
    "- In the end a note will be provided to clarify where to use which variant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7326838b",
   "metadata": {},
   "source": [
    "## Clarity Mapping\n",
    "### A clear LLM output:\n",
    "\n",
    "-Directly mentions the relevant organizations (by name).\n",
    "\n",
    "-Avoids overly verbose or vague phrasing.\n",
    "\n",
    "-Uses fewer unnecessary filler words.\n",
    "\n",
    "-Is grammatically correct and coherent.\n",
    "\n",
    "-Keeps token usage efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed86f5",
   "metadata": {},
   "source": [
    "#### Two Functions created to measure LLM output performance - \n",
    "- calculate_precision_recall for retriever\n",
    "- compute_clarity for LLM response\n",
    "\n",
    "these functions will help us better understand which prompt variation is best in terms of finding the best answer with good token efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85e82f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_ = { 'queries' : [\n",
    "    \"Which organizations show signs of potential money laundering?\",\n",
    "    \"Identify firms flagged for insider trading or suspicious market manipulation.\",\n",
    "    \"Which firms operate through complex shell company structures that may obscure transparency?\",\n",
    "    \"Which institutions demonstrate strong internal audits and transparent operations?\",\n",
    "    \"Find organizations that rely on opaque financial structures or mechanisms.\",\n",
    "    \"Identify low-risk institutions with a clean track record in compliance.\"\n",
    "],\n",
    "             'expected_outputs' : [\n",
    "    \"Aurora Financial Services,Gemini Asset Management\",\n",
    "    \"Blue Horizon Investments\",\n",
    "    \"Cascade Capital Management\",\n",
    "    \"Falcon Secure Bank,Jupiter Commodities Exchange,Kepler Financial Innovations,Lunar Investment Group\",\n",
    "    \"Aurora Financial Services,Cascade Capital Management\",\n",
    "    \"Delta Trade Corporation,Falcon Secure Bank,Lunar Investment Group,Kepler Financial Innovations,Ionex Brokerage Services\"\n",
    "             ]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a29b9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall(query, expected_orgs):\n",
    "    \"\"\"\n",
    "    Calculates precision and recall for retrieved documents based on expected organization matches.\n",
    "\n",
    "    This function uses a retriever to fetch documents based on a query and compares the titles\n",
    "    of the retrieved documents against a list of expected organization names. It calculates:\n",
    "    - Precision: Proportion of relevant organizations among the retrieved ones.\n",
    "    - Recall: Proportion of relevant organizations successfully retrieved.\n",
    "    - True Positives: Set of organizations correctly identified as relevant.\n",
    "\n",
    "    Args:\n",
    "        query (str): \n",
    "            The user query to retrieve documents for.\n",
    "        expected_orgs (str): \n",
    "            A comma-separated string of expected organization names.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - precision (float): Proportion of relevant documents among retrieved ones.\n",
    "            - recall (float): Proportion of relevant documents that were successfully retrieved.\n",
    "            - true_positives (set): Set of organization names that match both expected and retrieved titles.\n",
    "\n",
    "    Note:\n",
    "        - The function assumes the presence of a `retriever_mmr` object that returns documents\n",
    "          with metadata containing a 'title' field representing the organization name.\n",
    "    \"\"\"\n",
    "    retrieved_companies = []\n",
    "    retrieved_docs = retriever_mmr.invoke(query)\n",
    "    for i in retrieved_docs:\n",
    "        retrieved_companies.append(i.metadata['title'])\n",
    "    expected_orgs = expected_orgs.split(\",\")\n",
    "    expected_set = set(expected_orgs)\n",
    "    retrieved_set = set(retrieved_companies)\n",
    "\n",
    "    true_positives = expected_set.intersection(retrieved_set)\n",
    "      \n",
    "    precision = len(true_positives) / len(retrieved_companies) if retrieved_companies else 0\n",
    "    recall = len(true_positives) / len(expected_orgs) if expected_orgs else 0\n",
    "\n",
    "    return round(precision, 2), round(recall, 2), true_positives     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df497a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clarity(response, matches):\n",
    "    \"\"\"\n",
    "    Computes a clarity score for an LLM-generated response based on named entity density \n",
    "    and lexical repetition.\n",
    "\n",
    "    Clarity is evaluated as a combination of:\n",
    "    - Named Entity Density: The proportion of matched organization names\n",
    "      relative to the total word count in the response.\n",
    "    - Repetition Penalty: Penalizes excessive repetition of words in the output to \n",
    "      reward more informative and diverse content.\n",
    "\n",
    "    Args:\n",
    "        response (object): \n",
    "            An LLM response object containing the generated text.\n",
    "        matches (list of str): \n",
    "            A list of organization names (matched entities) found in the expected output.\n",
    "\n",
    "    Returns:\n",
    "        float:\n",
    "            A clarity score, where a higher value indicates clearer, denser, and \n",
    "            less repetitive output.\n",
    "\n",
    "    Notes:\n",
    "        - The function performs a basic cleaning by removing commas and line breaks before analysis.\n",
    "        - A higher named entity density and lower repetition lead to a higher clarity score.\n",
    "    \"\"\"\n",
    "    llm_output_clean = response.content.lower().replace(\",\", \" \").replace(\"\\n\", \" \")\n",
    "    # Named Entity Density\n",
    "    delimiter_space = \" \"\n",
    "    org_density = len(delimiter_space.join(matches).split()) / len(llm_output_clean.split())\n",
    "\n",
    "    # Repetition Penalty: count repeating words\n",
    "    words = re.findall(r'\\b\\w+\\b', llm_output_clean)\n",
    "    unique_words = set(words)\n",
    "    repetition_ratio = 1 - (len(unique_words) / len(words)) if words else 0\n",
    "\n",
    "    # Clarity = density * (1 - repetition penalty)\n",
    "    clarity_score = org_density * (1 - repetition_ratio)\n",
    "\n",
    "    return round(clarity_score * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b11ffe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine which prompt variant provides most relevance\n",
    "def llm_judge(query,expected_output,template_type):\n",
    "    \"\"\"\n",
    "    Evaluates a single LLM response pipeline using a given prompt template to determine \n",
    "    retrieval relevance, output clarity, and overall response quality.\n",
    "\n",
    "    This function:\n",
    "    - Runs a retrieval-augmented generation (RAG) pipeline using the specified query and prompt template.\n",
    "    - Measures response latency and token usage.\n",
    "    - Calculates retrieval precision and recall by comparing retrieved company names with the expected output.\n",
    "    - Computes clarity of the LLM's textual output based on named entity density and repetition.\n",
    "    - Prints a detailed breakdown of the performance, including matched companies and clarity score.\n",
    "\n",
    "    Args:\n",
    "        query (str): \n",
    "            The input query to evaluate (e.g., \"Which organizations show signs of money laundering?\").\n",
    "        expected_output (str): \n",
    "            A comma-separated string of expected organization names.\n",
    "        template_type (str): \n",
    "            The prompt template text used to format the query before passing it to the LLM.\n",
    "\n",
    "    Returns:\n",
    "        None: \n",
    "            The function prints a detailed analysis to the console, including:\n",
    "                - Retrieved companies\n",
    "                - LLM output\n",
    "                - Token consumption\n",
    "                - Precision and recall metrics\n",
    "                - Matched organizations\n",
    "                - Clarity score\n",
    "                - Response time in seconds\n",
    "\n",
    "    \"\"\"\n",
    "    prompt_template = PromptTemplate.from_template(template_type)\n",
    "    chain = ({'retrieved_documents':retriever_mmr,\n",
    "         'query':RunnablePassthrough()} | prompt_template | chat)\n",
    "    start_time = time.time()\n",
    "    response = chain.invoke(query)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    tokens_consumed = sum(response.additional_kwargs['token_count'].values())\n",
    "    retrieved_companies = retriever_mmr.invoke(query)\n",
    "    precision,recall,matches = calculate_precision_recall(query,expected_output)\n",
    "    print(f\"QUERY -> {query}\")\n",
    "    print(\"Retriever retrieved :\")\n",
    "    for i in retrieved_companies:\n",
    "        print(i.metadata['title'])\n",
    "    print(f\"\"\"\n",
    "    ------------------------------------      \n",
    "    expected companies = {expected_output}\n",
    "    ------------------------------------      \n",
    "    response : \n",
    "    {response.content}\n",
    "    ------------------------------------\n",
    "    total_tokens_consumed = {tokens_consumed}\n",
    "    ------------------------------------\n",
    "    retrieval precision = {precision}\n",
    "    retrieval recall = {recall}\n",
    "    ----------------------------------- \n",
    "    matched companies = {matches}\n",
    "    -----------------------------------\n",
    "    clarity_score = {compute_clarity(response,matches)}\n",
    "    ---------------------------------\n",
    "    Response Time (s): {round(elapsed_time, 2)} seconds\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c33b424a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base': '\\nUse the following context to answer the question:\\n{retrieved_documents}\\nQuestion: {query}\\nAnswer:\\n',\n",
       " 'risk_focused': '\\nYou are a compliance analyst. Based on the context below, \\nidentify any signs of financial crime or compliance risks.\\nContext:\\n{retrieved_documents}\\nQuery: {query}\\nResponse:\\n',\n",
       " 'regulatory tone with evaluation': '\\nAs a regulator, assess the following organizations based on context:\\n{retrieved_documents}\\n\\nFor each entity mentioned in the context:\\n- Assign a **Compliance Risk Level**: High, Medium, or Low\\n- Justify the rating in one sentence using evidence from the context.\\nBe precise, formal, and analytical.\\n\\nQuery: {query}\\nResponse:\\n',\n",
       " 'chain_of_thought': '\\nAnalyze the context below step by step and determine\\nif any organizations show patterns related to financial misconduct.\\nContext:\\n{retrieved_documents}\\nQuery: {query}\\nStep-by-step analysis:\\n',\n",
       " 'focused_extraction': '\\nRead the context below and extract only the organization names that \\nmatch the criteria in the query.\\nContext:\\n{retrieved_documents}\\nQuery: {query}\\nMatching organizations:\\n',\n",
       " 'summarize_analyze': '\\nSummarize the key characteristics of each organization in the context, \\nthen answer the query.\\nContext:\\n{retrieved_documents}\\nSummary + Answer:\\n'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee7624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_result_tables(prompt_templates, query, expected_output):\n",
    "    \"\"\"\n",
    "    Runs a retrieval-augmented generation (RAG) pipeline for multiple prompt templates and \n",
    "    evaluates the performance of each variant on a given query.\n",
    "\n",
    "    This function:\n",
    "    - Executes an LLM chain for each prompt template using the specified query.\n",
    "    - Measures token usage and response time.\n",
    "    - Computes retrieval precision and recall against an expected list of organizations.\n",
    "    - Calculates clarity of the LLM output using named entity density and repetition penalty.\n",
    "    - Collects retrieved company titles and matched entities.\n",
    "\n",
    "    Args:\n",
    "        prompt_templates (dict): \n",
    "            A dictionary where keys are template names and values are prompt template strings.\n",
    "        query (str): \n",
    "            The input query to be evaluated.\n",
    "        expected_output (str): \n",
    "            A comma-separated string of expected organization names.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: \n",
    "            A DataFrame where each row corresponds to a prompt template variant, \n",
    "            containing the following columns:\n",
    "                - \"Prompt Name\"\n",
    "                - \"Output\"\n",
    "                - \"Tokens Count - Input\"\n",
    "                - \"Tokens Count - Output\"\n",
    "                - \"Tokens Consumed\"\n",
    "                - \"Retrieval Precision\"\n",
    "                - \"Retrieval Recall\"\n",
    "                - \"Retrieved Companies\"\n",
    "                - \"matches\"\n",
    "                - \"clarity\"\n",
    "                - \"Response Time (s)\"\n",
    "\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for name, template in prompt_templates.items():\n",
    "        prompt_template = PromptTemplate.from_template(template)\n",
    "        # not added string output parser, to access the response object metadata\n",
    "        chain = ({'retrieved_documents':retriever_mmr,\n",
    "         'query':RunnablePassthrough()} | prompt_template | chat)\n",
    "\n",
    "        start_time = time.time()\n",
    "        response = chain.invoke(query)\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        token_usage = response.additional_kwargs['token_count']\n",
    "\n",
    "        retrieved_docs = retriever_mmr.invoke(query)\n",
    "        retrieved_companies = []\n",
    "        for i in retrieved_docs:\n",
    "            retrieved_companies.append(i.metadata['title'])\n",
    "            \n",
    "        precision,recall,matches = calculate_precision_recall(query,expected_output)\n",
    "\n",
    "        results.append({\n",
    "            \"Prompt Name\": name,\n",
    "            \"Output\": response.content,\n",
    "            \"Tokens Count - Input\": token_usage['input_tokens'],\n",
    "            \"Tokens Count - Output\": token_usage['output_tokens'],\n",
    "            \"Tokens Consumed\": sum(token_usage.values()),\n",
    "            \"Retrieval Precision\": precision,\n",
    "            \"Retrieval Recall\": recall,\n",
    "            \"Retrieved Companies\": retrieved_companies,\n",
    "            \"matches\": matches,\n",
    "            \"clarity\": compute_clarity(response,matches),\n",
    "            \"Response Time (s)\": round(elapsed_time, 2),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b3c452",
   "metadata": {},
   "source": [
    "#### Test Query 1 - Which organizations show signs of potential money laundering?\n",
    " Answer - 'Aurora Financial Services,Gemini Asset Management'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b803a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_results = generate_result_tables(prompt_templates, test_set_[\"queries\"][0], test_set_[\"expected_outputs\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "616ca0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt Name</th>\n",
       "      <th>Output</th>\n",
       "      <th>Tokens Count - Input</th>\n",
       "      <th>Tokens Count - Output</th>\n",
       "      <th>Tokens Consumed</th>\n",
       "      <th>Retrieval Precision</th>\n",
       "      <th>Retrieval Recall</th>\n",
       "      <th>Retrieved Companies</th>\n",
       "      <th>matches</th>\n",
       "      <th>clarity</th>\n",
       "      <th>Response Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>Based on the provided context, **Gemini Asset ...</td>\n",
       "      <td>786.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Gemini Asset Management, Gemini Asset Managem...</td>\n",
       "      <td>{Gemini Asset Management}</td>\n",
       "      <td>1.86</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>risk_focused</td>\n",
       "      <td>Based on the provided context, **Gemini Asset ...</td>\n",
       "      <td>804.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Gemini Asset Management, Gemini Asset Managem...</td>\n",
       "      <td>{Gemini Asset Management}</td>\n",
       "      <td>1.60</td>\n",
       "      <td>5.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regulatory tone with evaluation</td>\n",
       "      <td>### Compliance Risk Level Assessment:\\n\\n1. **...</td>\n",
       "      <td>839.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Gemini Asset Management, Gemini Asset Managem...</td>\n",
       "      <td>{Gemini Asset Management}</td>\n",
       "      <td>1.30</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chain_of_thought</td>\n",
       "      <td>To determine which organizations show signs of...</td>\n",
       "      <td>805.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Gemini Asset Management, Gemini Asset Managem...</td>\n",
       "      <td>{Gemini Asset Management}</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focused_extraction</td>\n",
       "      <td>Based on the context provided, the organizatio...</td>\n",
       "      <td>801.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Gemini Asset Management, Gemini Asset Managem...</td>\n",
       "      <td>{Gemini Asset Management}</td>\n",
       "      <td>4.09</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>summarize_analyze</td>\n",
       "      <td>### Summary of Key Characteristics:\\n\\n1. **Ge...</td>\n",
       "      <td>789.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Gemini Asset Management, Gemini Asset Managem...</td>\n",
       "      <td>{Gemini Asset Management}</td>\n",
       "      <td>1.13</td>\n",
       "      <td>6.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Prompt Name  \\\n",
       "0                             base   \n",
       "1                     risk_focused   \n",
       "2  regulatory tone with evaluation   \n",
       "3                 chain_of_thought   \n",
       "4               focused_extraction   \n",
       "5                summarize_analyze   \n",
       "\n",
       "                                              Output  Tokens Count - Input  \\\n",
       "0  Based on the provided context, **Gemini Asset ...                 786.0   \n",
       "1  Based on the provided context, **Gemini Asset ...                 804.0   \n",
       "2  ### Compliance Risk Level Assessment:\\n\\n1. **...                 839.0   \n",
       "3  To determine which organizations show signs of...                 805.0   \n",
       "4  Based on the context provided, the organizatio...                 801.0   \n",
       "5  ### Summary of Key Characteristics:\\n\\n1. **Ge...                 789.0   \n",
       "\n",
       "   Tokens Count - Output  Tokens Consumed  Retrieval Precision  \\\n",
       "0                  136.0            922.0                 0.25   \n",
       "1                  186.0            990.0                 0.25   \n",
       "2                  209.0           1048.0                 0.25   \n",
       "3                  362.0           1167.0                 0.25   \n",
       "4                   73.0            874.0                 0.25   \n",
       "5                  242.0           1031.0                 0.25   \n",
       "\n",
       "   Retrieval Recall                                Retrieved Companies  \\\n",
       "0               0.5  [Gemini Asset Management, Gemini Asset Managem...   \n",
       "1               0.5  [Gemini Asset Management, Gemini Asset Managem...   \n",
       "2               0.5  [Gemini Asset Management, Gemini Asset Managem...   \n",
       "3               0.5  [Gemini Asset Management, Gemini Asset Managem...   \n",
       "4               0.5  [Gemini Asset Management, Gemini Asset Managem...   \n",
       "5               0.5  [Gemini Asset Management, Gemini Asset Managem...   \n",
       "\n",
       "                     matches  clarity  Response Time (s)  \n",
       "0  {Gemini Asset Management}     1.86               4.31  \n",
       "1  {Gemini Asset Management}     1.60               5.02  \n",
       "2  {Gemini Asset Management}     1.30               5.80  \n",
       "3  {Gemini Asset Management}     0.54               8.96  \n",
       "4  {Gemini Asset Management}     4.09               2.49  \n",
       "5  {Gemini Asset Management}     1.13               6.63  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6bb953",
   "metadata": {},
   "source": [
    "#### Test Query 2 - Identify firms flagged for insider trading or suspicious market manipulation.\n",
    " Answer - 'Blue Horizon Investments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33056317",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_results = generate_result_tables(prompt_templates, test_set_[\"queries\"][1], test_set_[\"expected_outputs\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d672c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt Name</th>\n",
       "      <th>Output</th>\n",
       "      <th>Tokens Count - Input</th>\n",
       "      <th>Tokens Count - Output</th>\n",
       "      <th>Tokens Consumed</th>\n",
       "      <th>Retrieval Precision</th>\n",
       "      <th>Retrieval Recall</th>\n",
       "      <th>Retrieved Companies</th>\n",
       "      <th>matches</th>\n",
       "      <th>clarity</th>\n",
       "      <th>Response Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>Based on the provided context, the firm flagge...</td>\n",
       "      <td>784.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Eclipse Global Holdings, Eclipse Global Holdi...</td>\n",
       "      <td>{Blue Horizon Investments}</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>risk_focused</td>\n",
       "      <td>Based on the provided context, the firm flagge...</td>\n",
       "      <td>802.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Eclipse Global Holdings, Eclipse Global Holdi...</td>\n",
       "      <td>{Blue Horizon Investments}</td>\n",
       "      <td>6.19</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regulatory tone with evaluation</td>\n",
       "      <td>### Compliance Risk Level Assessments:\\n\\n1. *...</td>\n",
       "      <td>837.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Eclipse Global Holdings, Eclipse Global Holdi...</td>\n",
       "      <td>{Blue Horizon Investments}</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chain_of_thought</td>\n",
       "      <td>To determine if any organizations show pattern...</td>\n",
       "      <td>803.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Eclipse Global Holdings, Eclipse Global Holdi...</td>\n",
       "      <td>{Blue Horizon Investments}</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focused_extraction</td>\n",
       "      <td>Based on the query criteria, the organization ...</td>\n",
       "      <td>799.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Eclipse Global Holdings, Eclipse Global Holdi...</td>\n",
       "      <td>{Blue Horizon Investments}</td>\n",
       "      <td>14.21</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>summarize_analyze</td>\n",
       "      <td>### Summary of Key Characteristics:\\n\\n1. **Ec...</td>\n",
       "      <td>785.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Eclipse Global Holdings, Eclipse Global Holdi...</td>\n",
       "      <td>{Blue Horizon Investments}</td>\n",
       "      <td>1.17</td>\n",
       "      <td>5.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Prompt Name  \\\n",
       "0                             base   \n",
       "1                     risk_focused   \n",
       "2  regulatory tone with evaluation   \n",
       "3                 chain_of_thought   \n",
       "4               focused_extraction   \n",
       "5                summarize_analyze   \n",
       "\n",
       "                                              Output  Tokens Count - Input  \\\n",
       "0  Based on the provided context, the firm flagge...                 784.0   \n",
       "1  Based on the provided context, the firm flagge...                 802.0   \n",
       "2  ### Compliance Risk Level Assessments:\\n\\n1. *...                 837.0   \n",
       "3  To determine if any organizations show pattern...                 803.0   \n",
       "4  Based on the query criteria, the organization ...                 799.0   \n",
       "5  ### Summary of Key Characteristics:\\n\\n1. **Ec...                 785.0   \n",
       "\n",
       "   Tokens Count - Output  Tokens Consumed  Retrieval Precision  \\\n",
       "0                   54.0            838.0                 0.25   \n",
       "1                   55.0            857.0                 0.25   \n",
       "2                  185.0           1022.0                 0.25   \n",
       "3                  449.0           1252.0                 0.25   \n",
       "4                   28.0            827.0                 0.25   \n",
       "5                  227.0           1012.0                 0.25   \n",
       "\n",
       "   Retrieval Recall                                Retrieved Companies  \\\n",
       "0               1.0  [Eclipse Global Holdings, Eclipse Global Holdi...   \n",
       "1               1.0  [Eclipse Global Holdings, Eclipse Global Holdi...   \n",
       "2               1.0  [Eclipse Global Holdings, Eclipse Global Holdi...   \n",
       "3               1.0  [Eclipse Global Holdings, Eclipse Global Holdi...   \n",
       "4               1.0  [Eclipse Global Holdings, Eclipse Global Holdi...   \n",
       "5               1.0  [Eclipse Global Holdings, Eclipse Global Holdi...   \n",
       "\n",
       "                      matches  clarity  Response Time (s)  \n",
       "0  {Blue Horizon Investments}     5.25               1.98  \n",
       "1  {Blue Horizon Investments}     6.19               2.05  \n",
       "2  {Blue Horizon Investments}     1.50               4.97  \n",
       "3  {Blue Horizon Investments}     0.44              10.85  \n",
       "4  {Blue Horizon Investments}    14.21               1.38  \n",
       "5  {Blue Horizon Investments}     1.17               5.96  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cb13eb",
   "metadata": {},
   "source": [
    "#### Test Query 3 - Which firms operate through complex shell company structures that may obscure transparency?\n",
    " Answer - 'Cascade Capital Management'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a871c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_results = generate_result_tables(prompt_templates, test_set_[\"queries\"][2], test_set_[\"expected_outputs\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d60d30fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt Name</th>\n",
       "      <th>Output</th>\n",
       "      <th>Tokens Count - Input</th>\n",
       "      <th>Tokens Count - Output</th>\n",
       "      <th>Tokens Consumed</th>\n",
       "      <th>Retrieval Precision</th>\n",
       "      <th>Retrieval Recall</th>\n",
       "      <th>Retrieved Companies</th>\n",
       "      <th>matches</th>\n",
       "      <th>clarity</th>\n",
       "      <th>Response Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>Based on the provided context, **Cascade Capit...</td>\n",
       "      <td>787.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Cascade Capital Management, Cascade Capital M...</td>\n",
       "      <td>{Cascade Capital Management}</td>\n",
       "      <td>5.25</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>risk_focused</td>\n",
       "      <td>Based on the provided context, **Cascade Capit...</td>\n",
       "      <td>805.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Cascade Capital Management, Cascade Capital M...</td>\n",
       "      <td>{Cascade Capital Management}</td>\n",
       "      <td>1.30</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regulatory tone with evaluation</td>\n",
       "      <td>**Compliance Risk Assessment:**\\n\\n1. **Cascad...</td>\n",
       "      <td>840.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Cascade Capital Management, Cascade Capital M...</td>\n",
       "      <td>{Cascade Capital Management}</td>\n",
       "      <td>1.83</td>\n",
       "      <td>5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chain_of_thought</td>\n",
       "      <td>**Step 1: Identify the organizations mentioned...</td>\n",
       "      <td>806.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Cascade Capital Management, Cascade Capital M...</td>\n",
       "      <td>{Cascade Capital Management}</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focused_extraction</td>\n",
       "      <td>Based on the provided context, the organizatio...</td>\n",
       "      <td>802.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Cascade Capital Management, Cascade Capital M...</td>\n",
       "      <td>{Cascade Capital Management}</td>\n",
       "      <td>11.86</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>summarize_analyze</td>\n",
       "      <td>### Summary of Key Characteristics:\\n\\n1. **Ca...</td>\n",
       "      <td>786.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Cascade Capital Management, Cascade Capital M...</td>\n",
       "      <td>{Cascade Capital Management}</td>\n",
       "      <td>0.91</td>\n",
       "      <td>7.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Prompt Name  \\\n",
       "0                             base   \n",
       "1                     risk_focused   \n",
       "2  regulatory tone with evaluation   \n",
       "3                 chain_of_thought   \n",
       "4               focused_extraction   \n",
       "5                summarize_analyze   \n",
       "\n",
       "                                              Output  Tokens Count - Input  \\\n",
       "0  Based on the provided context, **Cascade Capit...                 787.0   \n",
       "1  Based on the provided context, **Cascade Capit...                 805.0   \n",
       "2  **Compliance Risk Assessment:**\\n\\n1. **Cascad...                 840.0   \n",
       "3  **Step 1: Identify the organizations mentioned...                 806.0   \n",
       "4  Based on the provided context, the organizatio...                 802.0   \n",
       "5  ### Summary of Key Characteristics:\\n\\n1. **Ca...                 786.0   \n",
       "\n",
       "   Tokens Count - Output  Tokens Consumed  Retrieval Precision  \\\n",
       "0                   62.0            849.0                 0.25   \n",
       "1                  214.0           1019.0                 0.25   \n",
       "2                  182.0           1022.0                 0.25   \n",
       "3                  341.0           1147.0                 0.25   \n",
       "4                   31.0            833.0                 0.25   \n",
       "5                  282.0           1068.0                 0.25   \n",
       "\n",
       "   Retrieval Recall                                Retrieved Companies  \\\n",
       "0               1.0  [Cascade Capital Management, Cascade Capital M...   \n",
       "1               1.0  [Cascade Capital Management, Cascade Capital M...   \n",
       "2               1.0  [Cascade Capital Management, Cascade Capital M...   \n",
       "3               1.0  [Cascade Capital Management, Cascade Capital M...   \n",
       "4               1.0  [Cascade Capital Management, Cascade Capital M...   \n",
       "5               1.0  [Cascade Capital Management, Cascade Capital M...   \n",
       "\n",
       "                        matches  clarity  Response Time (s)  \n",
       "0  {Cascade Capital Management}     5.25               2.07  \n",
       "1  {Cascade Capital Management}     1.30               5.80  \n",
       "2  {Cascade Capital Management}     1.83               5.20  \n",
       "3  {Cascade Capital Management}     0.52               9.79  \n",
       "4  {Cascade Capital Management}    11.86               1.42  \n",
       "5  {Cascade Capital Management}     0.91               7.86  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef51ed",
   "metadata": {},
   "source": [
    "#### Test Query 4 - Which institutions demonstrate strong internal audits and transparent operations?\n",
    " Answer - 'Falcon Secure Bank,Jupiter Commodities Exchange,Kepler Financial Innovations,Lunar Investment Group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "908ed485",
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_results = generate_result_tables(prompt_templates, test_set_[\"queries\"][3], test_set_[\"expected_outputs\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ffe05a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt Name</th>\n",
       "      <th>Output</th>\n",
       "      <th>Tokens Count - Input</th>\n",
       "      <th>Tokens Count - Output</th>\n",
       "      <th>Tokens Consumed</th>\n",
       "      <th>Retrieval Precision</th>\n",
       "      <th>Retrieval Recall</th>\n",
       "      <th>Retrieved Companies</th>\n",
       "      <th>matches</th>\n",
       "      <th>clarity</th>\n",
       "      <th>Response Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>Based on the provided context, the institution...</td>\n",
       "      <td>795.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>979.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Falcon Secure Bank, Falcon Secure Bank, Delta...</td>\n",
       "      <td>{Falcon Secure Bank, Kepler Financial Innovati...</td>\n",
       "      <td>2.29</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>risk_focused</td>\n",
       "      <td>Based on the provided context, the following i...</td>\n",
       "      <td>813.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Falcon Secure Bank, Falcon Secure Bank, Delta...</td>\n",
       "      <td>{Falcon Secure Bank, Kepler Financial Innovati...</td>\n",
       "      <td>1.87</td>\n",
       "      <td>5.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regulatory tone with evaluation</td>\n",
       "      <td>### Compliance Risk Level Assessment:\\n\\n1. **...</td>\n",
       "      <td>848.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Falcon Secure Bank, Falcon Secure Bank, Delta...</td>\n",
       "      <td>{Falcon Secure Bank, Kepler Financial Innovati...</td>\n",
       "      <td>2.08</td>\n",
       "      <td>5.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chain_of_thought</td>\n",
       "      <td>To determine which institutions demonstrate st...</td>\n",
       "      <td>814.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Falcon Secure Bank, Falcon Secure Bank, Delta...</td>\n",
       "      <td>{Falcon Secure Bank, Kepler Financial Innovati...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>12.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focused_extraction</td>\n",
       "      <td>Based on the provided context, the organizatio...</td>\n",
       "      <td>810.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Falcon Secure Bank, Falcon Secure Bank, Delta...</td>\n",
       "      <td>{Falcon Secure Bank, Kepler Financial Innovati...</td>\n",
       "      <td>12.96</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>summarize_analyze</td>\n",
       "      <td>### Summary of Key Characteristics:\\n\\n1. **Fa...</td>\n",
       "      <td>797.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Falcon Secure Bank, Falcon Secure Bank, Delta...</td>\n",
       "      <td>{Falcon Secure Bank, Kepler Financial Innovati...</td>\n",
       "      <td>2.39</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Prompt Name  \\\n",
       "0                             base   \n",
       "1                     risk_focused   \n",
       "2  regulatory tone with evaluation   \n",
       "3                 chain_of_thought   \n",
       "4               focused_extraction   \n",
       "5                summarize_analyze   \n",
       "\n",
       "                                              Output  Tokens Count - Input  \\\n",
       "0  Based on the provided context, the institution...                 795.0   \n",
       "1  Based on the provided context, the following i...                 813.0   \n",
       "2  ### Compliance Risk Level Assessment:\\n\\n1. **...                 848.0   \n",
       "3  To determine which institutions demonstrate st...                 814.0   \n",
       "4  Based on the provided context, the organizatio...                 810.0   \n",
       "5  ### Summary of Key Characteristics:\\n\\n1. **Fa...                 797.0   \n",
       "\n",
       "   Tokens Count - Output  Tokens Consumed  Retrieval Precision  \\\n",
       "0                  184.0            979.0                  0.5   \n",
       "1                  232.0           1045.0                  0.5   \n",
       "2                  221.0           1069.0                  0.5   \n",
       "3                  462.0           1276.0                  0.5   \n",
       "4                   52.0            862.0                  0.5   \n",
       "5                  273.0           1070.0                  0.5   \n",
       "\n",
       "   Retrieval Recall                                Retrieved Companies  \\\n",
       "0               0.5  [Falcon Secure Bank, Falcon Secure Bank, Delta...   \n",
       "1               0.5  [Falcon Secure Bank, Falcon Secure Bank, Delta...   \n",
       "2               0.5  [Falcon Secure Bank, Falcon Secure Bank, Delta...   \n",
       "3               0.5  [Falcon Secure Bank, Falcon Secure Bank, Delta...   \n",
       "4               0.5  [Falcon Secure Bank, Falcon Secure Bank, Delta...   \n",
       "5               0.5  [Falcon Secure Bank, Falcon Secure Bank, Delta...   \n",
       "\n",
       "                                             matches  clarity  \\\n",
       "0  {Falcon Secure Bank, Kepler Financial Innovati...     2.29   \n",
       "1  {Falcon Secure Bank, Kepler Financial Innovati...     1.87   \n",
       "2  {Falcon Secure Bank, Kepler Financial Innovati...     2.08   \n",
       "3  {Falcon Secure Bank, Kepler Financial Innovati...     0.84   \n",
       "4  {Falcon Secure Bank, Kepler Financial Innovati...    12.96   \n",
       "5  {Falcon Secure Bank, Kepler Financial Innovati...     2.39   \n",
       "\n",
       "   Response Time (s)  \n",
       "0               4.62  \n",
       "1               5.57  \n",
       "2               5.57  \n",
       "3              12.18  \n",
       "4               1.87  \n",
       "5               7.06  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134be74c",
   "metadata": {},
   "source": [
    "#### Test Query 5 - Find organizations that rely on opaque financial structures or mechanisms.\n",
    " Answer - 'Aurora Financial Services,Cascade Capital Management'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b123d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_results = generate_result_tables(prompt_templates, test_set_[\"queries\"][4], test_set_[\"expected_outputs\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6dd76a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt Name</th>\n",
       "      <th>Output</th>\n",
       "      <th>Tokens Count - Input</th>\n",
       "      <th>Tokens Count - Output</th>\n",
       "      <th>Tokens Consumed</th>\n",
       "      <th>Retrieval Precision</th>\n",
       "      <th>Retrieval Recall</th>\n",
       "      <th>Retrieved Companies</th>\n",
       "      <th>matches</th>\n",
       "      <th>clarity</th>\n",
       "      <th>Response Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>Based on the provided context, the organizatio...</td>\n",
       "      <td>790.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Eclipse Global Holdings, Eclipse Global Holdi...</td>\n",
       "      <td>{Cascade Capital Management}</td>\n",
       "      <td>1.75</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>risk_focused</td>\n",
       "      <td>Based on the provided context, the following o...</td>\n",
       "      <td>808.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Eclipse Global Holdings, Eclipse Global Holdi...</td>\n",
       "      <td>{Cascade Capital Management}</td>\n",
       "      <td>0.68</td>\n",
       "      <td>7.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regulatory tone with evaluation</td>\n",
       "      <td>**Assessment of Organizations Based on Complia...</td>\n",
       "      <td>843.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Eclipse Global Holdings, Eclipse Global Holdi...</td>\n",
       "      <td>{Cascade Capital Management}</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chain_of_thought</td>\n",
       "      <td>To determine if any organizations show pattern...</td>\n",
       "      <td>809.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Eclipse Global Holdings, Eclipse Global Holdi...</td>\n",
       "      <td>{Cascade Capital Management}</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focused_extraction</td>\n",
       "      <td>Based on the provided context, the organizatio...</td>\n",
       "      <td>805.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Eclipse Global Holdings, Eclipse Global Holdi...</td>\n",
       "      <td>{Cascade Capital Management}</td>\n",
       "      <td>5.33</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>summarize_analyze</td>\n",
       "      <td>### Summary of Key Characteristics:\\n\\n1. **Ec...</td>\n",
       "      <td>791.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[Eclipse Global Holdings, Eclipse Global Holdi...</td>\n",
       "      <td>{Cascade Capital Management}</td>\n",
       "      <td>1.14</td>\n",
       "      <td>5.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Prompt Name  \\\n",
       "0                             base   \n",
       "1                     risk_focused   \n",
       "2  regulatory tone with evaluation   \n",
       "3                 chain_of_thought   \n",
       "4               focused_extraction   \n",
       "5                summarize_analyze   \n",
       "\n",
       "                                              Output  Tokens Count - Input  \\\n",
       "0  Based on the provided context, the organizatio...                 790.0   \n",
       "1  Based on the provided context, the following o...                 808.0   \n",
       "2  **Assessment of Organizations Based on Complia...                 843.0   \n",
       "3  To determine if any organizations show pattern...                 809.0   \n",
       "4  Based on the provided context, the organizatio...                 805.0   \n",
       "5  ### Summary of Key Characteristics:\\n\\n1. **Ec...                 791.0   \n",
       "\n",
       "   Tokens Count - Output  Tokens Consumed  Retrieval Precision  \\\n",
       "0                  144.0            934.0                 0.25   \n",
       "1                  320.0           1128.0                 0.25   \n",
       "2                  231.0           1074.0                 0.25   \n",
       "3                  425.0           1234.0                 0.25   \n",
       "4                   74.0            879.0                 0.25   \n",
       "5                  220.0           1011.0                 0.25   \n",
       "\n",
       "   Retrieval Recall                                Retrieved Companies  \\\n",
       "0               0.5  [Eclipse Global Holdings, Eclipse Global Holdi...   \n",
       "1               0.5  [Eclipse Global Holdings, Eclipse Global Holdi...   \n",
       "2               0.5  [Eclipse Global Holdings, Eclipse Global Holdi...   \n",
       "3               0.5  [Eclipse Global Holdings, Eclipse Global Holdi...   \n",
       "4               0.5  [Eclipse Global Holdings, Eclipse Global Holdi...   \n",
       "5               0.5  [Eclipse Global Holdings, Eclipse Global Holdi...   \n",
       "\n",
       "                        matches  clarity  Response Time (s)  \n",
       "0  {Cascade Capital Management}     1.75               4.08  \n",
       "1  {Cascade Capital Management}     0.68               7.96  \n",
       "2  {Cascade Capital Management}     1.10               5.57  \n",
       "3  {Cascade Capital Management}     0.43               9.24  \n",
       "4  {Cascade Capital Management}     5.33               2.46  \n",
       "5  {Cascade Capital Management}     1.14               5.95  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q5_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c48cc4",
   "metadata": {},
   "source": [
    "#### Test Query 6 - Identify low-risk institutions with a clean track record in compliance.\n",
    " Answer - 'Delta Trade Corporation,Falcon Secure Bank,Lunar Investment Group,Kepler Financial Innovations,Ionex Brokerage Services'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fa5fb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "q6_results = generate_result_tables(prompt_templates, test_set_[\"queries\"][5], test_set_[\"expected_outputs\"][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1c474d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt Name</th>\n",
       "      <th>Output</th>\n",
       "      <th>Tokens Count - Input</th>\n",
       "      <th>Tokens Count - Output</th>\n",
       "      <th>Tokens Consumed</th>\n",
       "      <th>Retrieval Precision</th>\n",
       "      <th>Retrieval Recall</th>\n",
       "      <th>Retrieved Companies</th>\n",
       "      <th>matches</th>\n",
       "      <th>clarity</th>\n",
       "      <th>Response Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>Based on the provided context, the following i...</td>\n",
       "      <td>794.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[Delta Trade Corporation, Delta Trade Corporat...</td>\n",
       "      <td>{Delta Trade Corporation, Falcon Secure Bank, ...</td>\n",
       "      <td>5.08</td>\n",
       "      <td>4.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>risk_focused</td>\n",
       "      <td>Based on the provided context, the following i...</td>\n",
       "      <td>812.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[Delta Trade Corporation, Delta Trade Corporat...</td>\n",
       "      <td>{Delta Trade Corporation, Falcon Secure Bank, ...</td>\n",
       "      <td>3.13</td>\n",
       "      <td>6.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regulatory tone with evaluation</td>\n",
       "      <td>**Delta Trade Corporation**  \\n**Compliance Ri...</td>\n",
       "      <td>847.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[Delta Trade Corporation, Delta Trade Corporat...</td>\n",
       "      <td>{Delta Trade Corporation, Falcon Secure Bank, ...</td>\n",
       "      <td>3.49</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chain_of_thought</td>\n",
       "      <td>To determine if any organizations show pattern...</td>\n",
       "      <td>813.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[Delta Trade Corporation, Delta Trade Corporat...</td>\n",
       "      <td>{Delta Trade Corporation, Falcon Secure Bank, ...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>13.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>focused_extraction</td>\n",
       "      <td>Based on the query to identify low-risk instit...</td>\n",
       "      <td>809.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[Delta Trade Corporation, Delta Trade Corporat...</td>\n",
       "      <td>{Delta Trade Corporation, Falcon Secure Bank, ...</td>\n",
       "      <td>10.55</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>summarize_analyze</td>\n",
       "      <td>### Summary of Key Characteristics:\\n\\n1. **De...</td>\n",
       "      <td>793.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[Delta Trade Corporation, Delta Trade Corporat...</td>\n",
       "      <td>{Delta Trade Corporation, Falcon Secure Bank, ...</td>\n",
       "      <td>3.02</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Prompt Name  \\\n",
       "0                             base   \n",
       "1                     risk_focused   \n",
       "2  regulatory tone with evaluation   \n",
       "3                 chain_of_thought   \n",
       "4               focused_extraction   \n",
       "5                summarize_analyze   \n",
       "\n",
       "                                              Output  Tokens Count - Input  \\\n",
       "0  Based on the provided context, the following i...                 794.0   \n",
       "1  Based on the provided context, the following i...                 812.0   \n",
       "2  **Delta Trade Corporation**  \\n**Compliance Ri...                 847.0   \n",
       "3  To determine if any organizations show pattern...                 813.0   \n",
       "4  Based on the query to identify low-risk instit...                 809.0   \n",
       "5  ### Summary of Key Characteristics:\\n\\n1. **De...                 793.0   \n",
       "\n",
       "   Tokens Count - Output  Tokens Consumed  Retrieval Precision  \\\n",
       "0                  181.0            975.0                 0.75   \n",
       "1                  248.0           1060.0                 0.75   \n",
       "2                  229.0           1076.0                 0.75   \n",
       "3                  544.0           1357.0                 0.75   \n",
       "4                   89.0            898.0                 0.75   \n",
       "5                  270.0           1063.0                 0.75   \n",
       "\n",
       "   Retrieval Recall                                Retrieved Companies  \\\n",
       "0               0.6  [Delta Trade Corporation, Delta Trade Corporat...   \n",
       "1               0.6  [Delta Trade Corporation, Delta Trade Corporat...   \n",
       "2               0.6  [Delta Trade Corporation, Delta Trade Corporat...   \n",
       "3               0.6  [Delta Trade Corporation, Delta Trade Corporat...   \n",
       "4               0.6  [Delta Trade Corporation, Delta Trade Corporat...   \n",
       "5               0.6  [Delta Trade Corporation, Delta Trade Corporat...   \n",
       "\n",
       "                                             matches  clarity  \\\n",
       "0  {Delta Trade Corporation, Falcon Secure Bank, ...     5.08   \n",
       "1  {Delta Trade Corporation, Falcon Secure Bank, ...     3.13   \n",
       "2  {Delta Trade Corporation, Falcon Secure Bank, ...     3.49   \n",
       "3  {Delta Trade Corporation, Falcon Secure Bank, ...     0.95   \n",
       "4  {Delta Trade Corporation, Falcon Secure Bank, ...    10.55   \n",
       "5  {Delta Trade Corporation, Falcon Secure Bank, ...     3.02   \n",
       "\n",
       "   Response Time (s)  \n",
       "0               4.47  \n",
       "1               6.56  \n",
       "2               5.47  \n",
       "3              13.77  \n",
       "4               2.89  \n",
       "5               7.06  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q6_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2870634c",
   "metadata": {},
   "source": [
    "### Final Observations: These four are reliable with their own pros and cons, Chose as per the usecase :\n",
    "\n",
    "#### Chain-of-Thought \n",
    "\n",
    "- It consistently produces the most detailed responses (highest output tokens) but also has the longest response times, going up to 15.88 seconds .\n",
    "- Excellent for nuanced analysis, but trade-off is speed and token consumption.\n",
    "\n",
    "#### Focused Extraction \n",
    "\n",
    "- Despite being the most concise (lowest output tokens), it shines in precision when targeting specific entities.\n",
    "- Clarity ratings are  high, implying the response is crisp and easy to interpret despite being short.\n",
    "\n",
    "#### Regulatory Tone with Evaluation -  Balances Formality & Utility\n",
    "\n",
    "- Strong middle ground across precision, clarity, and response time.\n",
    "- Presents data in a compliance-report format, ideal for risk evaluation dashboards.\n",
    "\n",
    "#### Summarize_Analyze \n",
    "\n",
    "- Moderate in everything— token usage, response time, clarity, and entity retrieval.\n",
    "- Great default mode for dashboards that need balanced insights without extremes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d4c07",
   "metadata": {},
   "source": [
    "### Some output examples -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9021dbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY -> Which organizations show signs of potential money laundering?\n",
      "Retriever retrieved :\n",
      "Gemini Asset Management\n",
      "Gemini Asset Management\n",
      "Eclipse Global Holdings\n",
      "Cascade Capital Management\n",
      "\n",
      "    ------------------------------------      \n",
      "    expected companies = Aurora Financial Services,Gemini Asset Management\n",
      "    ------------------------------------      \n",
      "    response : \n",
      "    Based on the provided context, **Gemini Asset Management** shows signs of potential money laundering. The key indicators include:\n",
      "\n",
      "1. **Unusually High Commissions**: Excessive or unexplained commissions can be a red flag for money laundering, as they may be used to disguise illicit funds as legitimate income.  \n",
      "2. **Inconsistent Portfolio Reporting**: Inconsistencies in reporting can indicate attempts to obfuscate the true source or movement of funds, a common tactic in money laundering schemes.  \n",
      "\n",
      "These anomalies have sparked concerns over potential money laundering and fraudulent practices, making Gemini Asset Management the organization in question for such risks.  \n",
      "\n",
      "While **Eclipse Global Holdings** and **Cascade Capital Management** exhibit compliance risks (e.g., suspected kickback schemes and complex shell company structures), there is no direct evidence in the provided context linking them to potential money laundering.\n",
      "    ------------------------------------\n",
      "    total_tokens_consumed = 978.0\n",
      "    ------------------------------------\n",
      "    retrieval precision = 0.25\n",
      "    retrieval recall = 0.5\n",
      "    ----------------------------------- \n",
      "    matched companies = {'Gemini Asset Management'}\n",
      "    -----------------------------------\n",
      "    clarity_score = 1.62\n",
      "    ---------------------------------\n",
      "    Response Time (s): 4.92 seconds\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "llm_judge(test_set_[\"queries\"][0],test_set_[\"expected_outputs\"][0],prompt_templates['risk_focused'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f30eba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY -> Identify firms flagged for insider trading or suspicious market manipulation.\n",
      "Retriever retrieved :\n",
      "Eclipse Global Holdings\n",
      "Eclipse Global Holdings\n",
      "Gemini Asset Management\n",
      "Blue Horizon Investments\n",
      "\n",
      "    ------------------------------------      \n",
      "    expected companies = Blue Horizon Investments\n",
      "    ------------------------------------      \n",
      "    response : \n",
      "    To determine if any organizations show patterns related to financial misconduct, specifically insider trading or suspicious market manipulation, let's analyze the provided context step by step:\n",
      "\n",
      "---\n",
      "\n",
      "### **Step 1: Review Each Document for Relevant Information**\n",
      "1. **Eclipse Global Holdings (Document 3)**  \n",
      "   - Linked to irregular contract awards and suspected kickback schemes.  \n",
      "   - Concerns about internal controls.  \n",
      "   - **No mention of insider trading or market manipulation.**  \n",
      "\n",
      "2. **Gemini Asset Management (Document 4)**  \n",
      "   - Spotlighted for unusually high commissions and inconsistent portfolio reporting.  \n",
      "   - Concerns over potential money laundering and fraudulent practices.  \n",
      "   - **No mention of insider trading or market manipulation.**  \n",
      "\n",
      "3. **Blue Horizon Investments (Document 1)**  \n",
      "   - Known for irregular transaction patterns and rapid, unexplained fund movements.  \n",
      "   - Concerns about possible insider trading and manipulation.  \n",
      "   - **Directly flagged for insider trading and market manipulation.**  \n",
      "\n",
      "---\n",
      "\n",
      "### **Step 2: Identify Firms Flagged for Insider Trading or Market Manipulation**\n",
      "Based on the analysis:  \n",
      "- **Blue Horizon Investments** is the only firm explicitly flagged for insider trading and suspicious market manipulation.  \n",
      "\n",
      "---\n",
      "\n",
      "### **Step 3: Conclusion**\n",
      "**Blue Horizon Investments** shows patterns related to financial misconduct, specifically insider trading and market manipulation. No other organizations in the provided context are flagged for these specific issues.  \n",
      "\n",
      "---\n",
      "\n",
      "**Final Answer:**  \n",
      "**Blue Horizon Investments** is the firm flagged for insider trading and suspicious market manipulation.\n",
      "    ------------------------------------\n",
      "    total_tokens_consumed = 1124.0\n",
      "    ------------------------------------\n",
      "    retrieval precision = 0.25\n",
      "    retrieval recall = 1.0\n",
      "    ----------------------------------- \n",
      "    matched companies = {'Blue Horizon Investments'}\n",
      "    -----------------------------------\n",
      "    clarity_score = 0.68\n",
      "    ---------------------------------\n",
      "    Response Time (s): 8.39 seconds\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "llm_judge(test_set_[\"queries\"][1],test_set_[\"expected_outputs\"][1],prompt_templates['chain_of_thought'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "043e937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY -> Which institutions demonstrate strong internal audits and transparent operations?\n",
      "Retriever retrieved :\n",
      "Falcon Secure Bank\n",
      "Falcon Secure Bank\n",
      "Delta Trade Corporation\n",
      "Kepler Financial Innovations\n",
      "\n",
      "    ------------------------------------      \n",
      "    expected companies = Falcon Secure Bank,Jupiter Commodities Exchange,Kepler Financial Innovations,Lunar Investment Group\n",
      "    ------------------------------------      \n",
      "    response : \n",
      "    Based on the provided context, the organization that demonstrates strong internal audits and transparent operations is:\n",
      "\n",
      "- **Falcon Secure Bank**\n",
      "    ------------------------------------\n",
      "    total_tokens_consumed = 838.0\n",
      "    ------------------------------------\n",
      "    retrieval precision = 0.5\n",
      "    retrieval recall = 0.5\n",
      "    ----------------------------------- \n",
      "    matched companies = {'Falcon Secure Bank', 'Kepler Financial Innovations'}\n",
      "    -----------------------------------\n",
      "    clarity_score = 28.42\n",
      "    ---------------------------------\n",
      "    Response Time (s): 1.6 seconds\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "llm_judge(test_set_[\"queries\"][3],test_set_[\"expected_outputs\"][3],prompt_templates['focused_extraction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd13375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarising to compare different prompt variations average performance\n",
    "df = [q1_results,q2_results,q3_results,q4_results,q5_results,q6_results]\n",
    "full_df = pd.concat(df, ignore_index=True)\n",
    "summary = full_df.groupby('Prompt Name').agg({\n",
    "        'Tokens Count - Input': 'mean',\n",
    "        'Tokens Count - Output': 'mean',\n",
    "        'Tokens Consumed': 'mean',\n",
    "        'Retrieval Precision': 'mean',\n",
    "        'Retrieval Recall': 'mean',\n",
    "        'clarity': 'mean',\n",
    "        'Response Time (s)': 'mean'\n",
    "    }).reset_index()\n",
    "summary = summary.round(2)\n",
    "summary.columns = [\n",
    "        'Prompt Name',\n",
    "        'Average Tokens Count - Input',\n",
    "        'Average Tokens Count - Output',\n",
    "        'Average Tokens Consumed',\n",
    "        'Average Precision',\n",
    "        'Average Recall',\n",
    "        'Average Clarity Score',\n",
    "        'Average Response Time (s)'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5405f692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt Name</th>\n",
       "      <th>Average Tokens Count - Input</th>\n",
       "      <th>Average Tokens Count - Output</th>\n",
       "      <th>Average Tokens Consumed</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average Clarity Score</th>\n",
       "      <th>Average Response Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>789.33</td>\n",
       "      <td>126.83</td>\n",
       "      <td>916.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.68</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chain_of_thought</td>\n",
       "      <td>808.33</td>\n",
       "      <td>430.50</td>\n",
       "      <td>1238.83</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>focused_extraction</td>\n",
       "      <td>804.33</td>\n",
       "      <td>57.83</td>\n",
       "      <td>862.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.83</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regulatory tone with evaluation</td>\n",
       "      <td>842.33</td>\n",
       "      <td>209.50</td>\n",
       "      <td>1051.83</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.88</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>risk_focused</td>\n",
       "      <td>807.33</td>\n",
       "      <td>209.17</td>\n",
       "      <td>1016.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.46</td>\n",
       "      <td>5.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>summarize_analyze</td>\n",
       "      <td>790.17</td>\n",
       "      <td>252.33</td>\n",
       "      <td>1042.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.63</td>\n",
       "      <td>6.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Prompt Name  Average Tokens Count - Input  \\\n",
       "0                             base                        789.33   \n",
       "1                 chain_of_thought                        808.33   \n",
       "2               focused_extraction                        804.33   \n",
       "3  regulatory tone with evaluation                        842.33   \n",
       "4                     risk_focused                        807.33   \n",
       "5                summarize_analyze                        790.17   \n",
       "\n",
       "   Average Tokens Count - Output  Average Tokens Consumed  Average Precision  \\\n",
       "0                         126.83                   916.17               0.38   \n",
       "1                         430.50                  1238.83               0.38   \n",
       "2                          57.83                   862.17               0.38   \n",
       "3                         209.50                  1051.83               0.38   \n",
       "4                         209.17                  1016.50               0.38   \n",
       "5                         252.33                  1042.50               0.38   \n",
       "\n",
       "   Average Recall  Average Clarity Score  Average Response Time (s)  \n",
       "0            0.68                   3.58                       3.59  \n",
       "1            0.68                   0.62                      10.80  \n",
       "2            0.68                   9.83                       2.08  \n",
       "3            0.68                   1.88                       5.43  \n",
       "4            0.68                   2.46                       5.49  \n",
       "5            0.68                   1.63                       6.75  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lanchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
